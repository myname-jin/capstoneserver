// server.js
import express from "express";
import multer from "multer";
import sharp from "sharp";
import {
  readFileSync, existsSync, mkdirSync, readdirSync, unlinkSync
} from "fs";
import { join } from "path";

// MediaPipe (ESM OK)
import { FaceLandmarker, FilesetResolver } from "@mediapipe/tasks-vision";

// âš ï¸ ffmpeg-extract-framesëŠ” CJS default export â†’ í•¨ìˆ˜ ê·¸ëŒ€ë¡œ import
import extractFrames from "ffmpeg-extract-frames";

const app = express();
const port = 3000;

// ì •ì íŒŒì¼ ì„œë¹™ (index.html ë¯¸ë¦¬ë³´ê¸°/í…ŒìŠ¤íŠ¸ìš©)
app.use(express.static("."));

// ì—…ë¡œë“œ ì„¤ì •
const uploadDir = "./uploads";
if (!existsSync(uploadDir)) mkdirSync(uploadDir, { recursive: true });
const upload = multer({ dest: uploadDir });

let faceLandmarker = null;

// ëª¨ë¸ ë¡œë“œ
async function setupFaceLandmarker() {
  console.log("1) MediaPipe ëª¨ë¸ ë¡œë“œ ì¤‘â€¦");
  const fileset = await FilesetResolver.forVisionTasks(
    "./node_modules/@mediapipe/tasks-vision/wasm"
  );
  faceLandmarker = await FaceLandmarker.createFromOptions(fileset, {
    baseOptions: {
      modelAssetPath:
        "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
      delegate: "CPU",
    },
    runningMode: "IMAGE",
    numFaces: 1,
    outputFaceBlendshapes: true,
  });
  console.log("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ");
}

// í•œ ì¥ ë¶„ì„
async function analyzeImage(imagePath) {
  const fileBuffer = readFileSync(imagePath);
  const image = sharp(fileBuffer);
  const metadata = await image.metadata();
  const pixelData = await image.removeAlpha().raw().toBuffer();
  const mpImage = {
    data: new Uint8Array(pixelData),
    width: metadata.width,
    height: metadata.height,
  };
  const results = faceLandmarker.detect(mpImage);
  if (results.faceBlendshapes?.length > 0) {
    return processBlendshapes(results.faceBlendshapes[0].categories);
  }
  return { error: "ì–¼êµ´ ë¯¸ê²€ì¶œ" };
}

// ë¸”ë Œë“œì…°ì´í”„ â†’ ì§€í‘œ
function processBlendshapes(blendshapes) {
  const pick = (n) => blendshapes.find((s) => s.categoryName === n)?.score ?? 0;
  const gaze_h =
    (pick("eyeLookOutLeft") - pick("eyeLookInLeft") +
      (pick("eyeLookInRight") - pick("eyeLookOutRight"))) /
    2;
  const gaze_v =
    (pick("eyeLookUpLeft") - pick("eyeLookDownLeft") +
      (pick("eyeLookUpRight") - pick("eyeLookDownRight"))) /
    2;
  const smile =
    (pick("mouthSmileLeft") + pick("mouthSmileRight")) / 2;
  const frown =
    (pick("mouthFrownLeft") + pick("mouthFrownRight")) / 2;
  const brow_down =
    (pick("browDownLeft") + pick("browDownRight")) / 2;
  const jaw_open = pick("jawOpen");
  return { gaze_h, gaze_v, smile, frown, brow_down, jaw_open };
}

// ë¹„ë””ì˜¤ ì „ì²´ ë¶„ì„
async function analyzeVideoFile(videoPath) {
  const FRAME_DIR = "./frames";
  const FRAME_RATE = 5;
  const allResults = [];

  // í”„ë ˆì„ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
  if (!existsSync(FRAME_DIR)) mkdirSync(FRAME_DIR, { recursive: true });
  else readdirSync(FRAME_DIR).forEach((f) => unlinkSync(join(FRAME_DIR, f)));

  // âš ï¸ ffmpeg-extract-frames: default í•¨ìˆ˜ (ìœ„ì—ì„œ ì˜¬ë°”ë¡œ import í•¨)
  await extractFrames({
    input: videoPath,
    output: `${FRAME_DIR}/frame-%04d.jpg`,
    fps: FRAME_RATE,
  });
  const framePaths = readdirSync(FRAME_DIR)
    .filter((f) => f.endsWith(".jpg"))
    .map((f) => join(FRAME_DIR, f));

  for (let i = 0; i < framePaths.length; i++) {
    const path = framePaths[i];
    const time = i / FRAME_RATE;
    const data = await analyzeImage(path);
    data.time = time;
    allResults.push(data);
  }
  return allResults;
}

// í—¬ìŠ¤ì²´í¬/ì¤€ë¹„ìƒíƒœ í™•ì¸
app.get("/health", (_req, res) => {
  res.json({
    ok: true,
    modelLoaded: !!faceLandmarker,
  });
});

// ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
app.post("/upload", upload.single("videoFile"), async (req, res) => {
  if (!req.file) return res.status(400).send("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.");
  if (!faceLandmarker)
    return res.status(503).send("ì„œë²„ AI ëª¨ë¸ì´ ì•„ì§ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤.");

  const videoPath = req.file.path;
  try {
    const resultsJson = await analyzeVideoFile(videoPath);
    res.json(resultsJson);
  } catch (e) {
    res.status(500).send("ì„œë²„ ë‚´ë¶€ ì²˜ë¦¬ ì˜¤ë¥˜: " + e.message);
  } finally {
    try { unlinkSync(videoPath); } catch {}
  }
});

// ì„œë²„ ì‹œì‘
app.listen(port, async () => {
  try {
    await setupFaceLandmarker();
    console.log(`ğŸš€ http://localhost:${port} ì—ì„œ ì‹¤í–‰ ì¤‘`);
  } catch (e) {
    console.error("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", e);
    console.error("ì„œë²„ëŠ” ì¼œì¡Œì§€ë§Œ /upload ìš”ì²­ì€ ë§‰í ìˆ˜ ìˆìŠµë‹ˆë‹¤.");
  }
});
